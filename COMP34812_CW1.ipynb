{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "2-VVKNy1A78V"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# COMP34812 Coursework"
      ],
      "metadata": {
        "id": "A0Gkeq29AZHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Code"
      ],
      "metadata": {
        "id": "POlNDDbfAkao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA-frf9m4C88",
        "outputId": "20b439b7-e403-42ed-d7c7-6315e7efe625"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DWwPphY1GVuH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Path Constants"
      ],
      "metadata": {
        "id": "eKIsn3WgAtyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "MODEL_PATH = \"bert-base-uncased\"\n",
        "TRAINING_DATASET_LOCATION = \"/content/drive/MyDrive/NLU/train.csv\"\n",
        "DEV_DATASET_LOCATION = \"/content/drive/MyDrive//NLU/dev.csv\"\n",
        "EVAL_DATASET_LOCATION = \"/content/drive/MyDrive/NLU/AV_trial.csv\"\n",
        "TEST_DATASET_LOCATION = \"/content/drive/MyDrive/NLU/test.csv\"\n",
        "PREDICTION_DATASET_LOCATION = \"/content/drive/MyDrive/NLU/predictions.csv\"\n",
        "SAVED_MODEL_PATH = \"/content/drive/MyDrive/NLU/modelBaseTrain\""
      ],
      "metadata": {
        "id": "kTywLJQbGdt_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert Loading"
      ],
      "metadata": {
        "id": "2-VVKNy1A78V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tokeniser and Model from MODEL_PATH(Bert Base Uncased)\n",
        "bertTokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "bertModel = AutoModel.from_pretrained(MODEL_PATH)"
      ],
      "metadata": {
        "id": "To1JIuGK_maN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class Definitions"
      ],
      "metadata": {
        "id": "in3hhnZDA__E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Siamese Dataset Class for Model Training\n",
        "class SiameseDataset(Dataset):\n",
        "  def __init__(self, csvFile:str) -> None:\n",
        "    # df = pd.read_csv(csvFile)\n",
        "    # self.texts1 = df[\"text_1\"].tolist()\n",
        "    # self.texts2 = df[\"text_2\"].tolist()\n",
        "    # self.labels = df[\"label\"].tolist()\n",
        "\n",
        "    self.texts1 = []\n",
        "    self.texts2 = []\n",
        "    self.labels = []\n",
        "    with open(csvFile, newline='') as f:\n",
        "      reader = reader = csv.DictReader(f)\n",
        "      for row in reader:\n",
        "        self.texts1.append(row[\"text_1\"])\n",
        "        self.texts2.append(row[\"text_2\"])\n",
        "        self.labels.append(row[\"label\"])\n",
        "    self.labels = np.asfarray(self.labels)\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index:int) -> tuple[str,str,torch.Tensor]:\n",
        "    text1 = self.texts1[index]\n",
        "    text2 = self.texts2[index]\n",
        "    label = self.labels[index]\n",
        "    return text1, text2, torch.tensor(label)"
      ],
      "metadata": {
        "id": "f-i42J7UGfOm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Siamese Dataset Class for Inference\n",
        "class SiameseInferenceDataset(Dataset):\n",
        "  def __init__(self, csvFile:str) -> None:\n",
        "    # df = pd.read_csv(csvFile)\n",
        "    # self.texts1 = df[\"text_1\"].tolist()\n",
        "    # self.texts2 = df[\"text_2\"].tolist()\n",
        "\n",
        "    self.texts1 = []\n",
        "    self.texts2 = []\n",
        "    with open(csvFile, newline='', encoding='utf-8-sig') as f:\n",
        "      reader = reader = csv.DictReader(f)\n",
        "      for row in reader:\n",
        "        self.texts1.append(row['text_1'])\n",
        "        self.texts2.append(row['text_2'])\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.texts1)\n",
        "\n",
        "  def __getitem__(self, index:int) -> tuple[str,str]:\n",
        "    return self.texts1[index], self.texts2[index]"
      ],
      "metadata": {
        "id": "YTi8UzQJGaws"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Siamese Model, uses one base model to generate outputs for two inputs\n",
        "class SiameseModel(nn.Module):\n",
        "  def __init__(self, baseModel):\n",
        "    super(SiameseModel, self).__init__()\n",
        "    self.baseModel = baseModel\n",
        "\n",
        "  def forward(self, inputs1, inputs2):\n",
        "    output1 = self.baseModel(**inputs1).last_hidden_state[:, 0, :].squeeze()\n",
        "    output2 = self.baseModel(**inputs2).last_hidden_state[:, 0, :].squeeze()\n",
        "    return output1, output2"
      ],
      "metadata": {
        "id": "qIVvhiQrGiTk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contrastive Loss function for training\n",
        "class ContrastiveLoss(nn.Module):\n",
        "  def __init__(self, margin=1.0):\n",
        "    super(ContrastiveLoss, self).__init__()\n",
        "    # Margin value for interclass distance and intraclass spacing\n",
        "    self.margin = margin\n",
        "\n",
        "  def forward(self, outputs1, outputs2, labels):\n",
        "    distance = nn.functional.pairwise_distance(outputs1, outputs2, keepdim=True)\n",
        "    # Loss for similar labels\n",
        "    simLoss = (1 - labels) * torch.pow(distance, 2)\n",
        "    # Loss for dissimilar labels\n",
        "    diff = torch.clamp(self.margin - distance, min=0.0)\n",
        "    disLoss = (labels) * torch.pow(diff, 2)\n",
        "    # Total Loss\n",
        "    loss = torch.mean(simLoss + disLoss)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "f_XdKndxGjzc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model and Dataset Loading"
      ],
      "metadata": {
        "id": "KXXiAbPbBKYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train dataset\n",
        "dataset = SiameseDataset(TRAINING_DATASET_LOCATION)\n",
        "dataLoader = DataLoader(dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "i0Ep1ZsnBJkc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from bert base model\n",
        "siameseModel = SiameseModel(bertModel)\n",
        "\n",
        "optimiser = optim.Adam(siameseModel.parameters(), lr=1e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=3, gamma=0.1)\n",
        "\n",
        "lossFunction = ContrastiveLoss(margin = 1)"
      ],
      "metadata": {
        "id": "FuO6jKCjBSOr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "ZcAbeqItBWUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel(epochs, savePath):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Device: {device}\")\n",
        "  siameseModel.to(device)\n",
        "  for epoch in range(epochs):\n",
        "    batchLoss = 0\n",
        "    for text1, text2, labels in dataLoader:\n",
        "\n",
        "      # Tokenise inputs\n",
        "      inputs1 = bertTokenizer(text1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "      inputs2 = bertTokenizer(text2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "      # Map to device\n",
        "      inputs1 = inputs1.to(device)\n",
        "      inputs2 = inputs2.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "\n",
        "      optimiser.zero_grad()\n",
        "      # Generate outputs\n",
        "      output1, output2 = siameseModel(inputs1, inputs2)\n",
        "      # Calculate contrastive loss\n",
        "      loss = lossFunction(output1, output2, labels)\n",
        "      batchLoss += loss.item()\n",
        "      loss.backward()\n",
        "      optimiser.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"---------------------EPOCH {epoch+1} / {epochs}---------------------\")\n",
        "    print(f\"Batch Loss {batchLoss}\")\n",
        "\n",
        "  torch.save(siameseModel.state_dict(), savePath)"
      ],
      "metadata": {
        "id": "HylvWvvzpSMg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12473s on training set\n",
        "trainModel(10,\"/content/drive/MyDrive/NLU/modelBaseDev3\")"
      ],
      "metadata": {
        "id": "31uOP9wrGk0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b643182b-54c3-41fa-b460-73a5d91ce551"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e5492049ed05>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 12473s on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/NLU/modelBaseDev3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-be462c46dc8f>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epochs, savePath)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m# Calculate contrastive loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mbatchLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saved Model Loading"
      ],
      "metadata": {
        "id": "Uy18lQ15Ft7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model from saved file\n",
        "siameseModel = SiameseModel(bertModel)\n",
        "siameseModel.load_state_dict(torch.load(SAVED_MODEL_PATH))"
      ],
      "metadata": {
        "id": "6D2IwvRHO-4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409dff25-457c-4001-f4ef-bf2524ff5981"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "8NosOI1njkGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siameseModel.eval()\n",
        "\n",
        "# Create inference dataset, no labels\n",
        "inferenceDataset = SiameseInferenceDataset(EVAL_DATASET_LOCATION)\n",
        "inferenceDataLoader = DataLoader(inferenceDataset, batch_size=16, shuffle=True)\n",
        "predictions = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "siameseModel.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for text1, text2 in inferenceDataLoader:\n",
        "\n",
        "    inputs1 = bertTokenizer(text1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    inputs2 = bertTokenizer(text2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    inputs1 = inputs1.to(device)\n",
        "    inputs2 = inputs2.to(device)\n",
        "\n",
        "    outputs1, outputs2 = siameseModel(inputs1, inputs2)\n",
        "    distances = torch.nn.functional.pairwise_distance(outputs1, outputs2)\n",
        "    predictions.extend(distances.cpu().numpy())"
      ],
      "metadata": {
        "id": "Agy6gIp5JMO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80032950-8c3f-4143-b71a-6fb43aa2131f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "with open(PREDICTION_DATASET_LOCATION, newline='') as csvfile:\n",
        "  reader = csv.DictReader(csvfile)\n",
        "  for row in reader:\n",
        "    labels.append(row[\"prediction\"])\n",
        "labels = torch.tensor(np.asfarray(labels))\n",
        "\n",
        "accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "f1_score = torchmetrics.F1Score(task=\"binary\")\n",
        "precision = torchmetrics.Precision(task=\"binary\")\n",
        "recall = torchmetrics.Recall(task=\"binary\")\n",
        "mcc = torchmetrics.MatthewsCorrCoef(task=\"binary\")\n",
        "cohens_kappa = torchmetrics.CohenKappa(task=\"binary\")\n",
        "\n",
        "Testing = False\n",
        "for i in range(1,9):\n",
        "  print('threshold:',i/10)\n",
        "  threshold = i/10\n",
        "  predicted_labels = torch.tensor([1 if distance < threshold else 0 for distance in predictions])\n",
        "  print(f\"Accuracy: {accuracy(predicted_labels, labels):.2f}\")\n",
        "  if(Testing):\n",
        "    print(f\"Macro Precision: {precision(predicted_labels, labels):.2f}\")\n",
        "    print(f\"Macro Recall: {recall(predicted_labels, labels):.2f}\")\n",
        "    print(f\"Macro F1-Score: {f1_score(predicted_labels, labels):.2f}\")"
      ],
      "metadata": {
        "id": "2rXGNztQJN0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12362a2-cb8f-4f82-d29d-c50d245b5131"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold: 0.1\n",
            "Accuracy: 0.54\n",
            "threshold: 0.2\n",
            "Accuracy: 0.54\n",
            "threshold: 0.3\n",
            "Accuracy: 0.54\n",
            "threshold: 0.4\n",
            "Accuracy: 0.54\n",
            "threshold: 0.5\n",
            "Accuracy: 0.42\n",
            "threshold: 0.6\n",
            "Accuracy: 0.46\n",
            "threshold: 0.7\n",
            "Accuracy: 0.46\n",
            "threshold: 0.8\n",
            "Accuracy: 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate scores on threshold of 0.5\n",
        "predictedLabels = torch.tensor([1 if distance < 0.5 else 0 for distance in predictions])\n",
        "print(labels[:50], predictedLabels[:50])\n",
        "print(f\"Accuracy: {accuracy(predictedLabels, labels):.2f}\")\n",
        "print(f\"Macro Precision: {precision(predictedLabels, labels):.2f}\")\n",
        "print(f\"Macro Recall: {recall(predictedLabels, labels):.2f}\")\n",
        "print(f\"Macro F1-Score: {f1_score(predictedLabels, labels):.2f}\")\n",
        "print(f\"MCC: {mcc(predictedLabels, labels):.2f}\")\n",
        "print(f\"Cohens Kappa: {cohens_kappa(predictedLabels, labels):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaZ2G462oK-e",
        "outputId": "c5af7585-3cb1-495b-e580-655d9ca48fda"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
            "        0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.],\n",
            "       dtype=torch.float64) tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "        0, 0])\n",
            "Accuracy: 0.54\n",
            "Macro Precision: 0.50\n",
            "Macro Recall: 0.52\n",
            "Macro F1-Score: 0.51\n",
            "MCC: 0.08\n",
            "Cohens Kappa: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Output"
      ],
      "metadata": {
        "id": "bq2_YtwGjGI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siameseModel.eval()\n",
        "inferenceDataset = SiameseInferenceDataset(TEST_DATASET_LOCATION)\n",
        "inferenceDataLoader = DataLoader(inferenceDataset, batch_size=16, shuffle=True)\n",
        "predictions = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "siameseModel.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for text1, text2 in inferenceDataLoader:\n",
        "\n",
        "    inputs1 = bertTokenizer(text1, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "    inputs2 = bertTokenizer(text2, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    inputs1 = inputs1.to(device)\n",
        "    inputs2 = inputs2.to(device)\n",
        "\n",
        "    outputs1, outputs2 = siameseModel(inputs1, inputs2)\n",
        "    distances = torch.nn.functional.pairwise_distance(outputs1, outputs2)\n",
        "    predictions.extend(distances.cpu().numpy())\n",
        "\n",
        "predictedLabels = torch.tensor([1 if distance < 0.5 else 0 for distance in predictions])\n",
        "\n",
        "with open(\"Group_83_C.csv\", 'w', newline='') as csvfile:\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=['prediction'])\n",
        "  writer.writeheader()\n",
        "  for p in predictedLabels:\n",
        "    writer.writerow({'prediction': p.item()})\n",
        "labels = torch.tensor(np.asfarray(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP0mkjQzhJVd",
        "outputId": "ed3e7d81-30b2-4a4f-c20f-cc43bb2fbc7d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVpawL60kMES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}